{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.chdir("aaaaa")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>varsta</th>\n",
       "      <th>gen_coded</th>\n",
       "      <th>iesit_des</th>\n",
       "      <th>lucrati</th>\n",
       "      <th>comportamentul</th>\n",
       "      <th>scor_motive_nu</th>\n",
       "      <th>scor_motive_da</th>\n",
       "      <th>ok_actiuni_1</th>\n",
       "      <th>confuz_1</th>\n",
       "      <th>...</th>\n",
       "      <th>P_1</th>\n",
       "      <th>P_2</th>\n",
       "      <th>schimbat</th>\n",
       "      <th>len_motive_nu</th>\n",
       "      <th>len_motive_da</th>\n",
       "      <th>scor_em_neg_inainte</th>\n",
       "      <th>scor_em_neg_dupa</th>\n",
       "      <th>scor_diferenta_b_a</th>\n",
       "      <th>sum_motive_nu</th>\n",
       "      <th>sum_motive_da</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80, 100, 100, 60</td>\n",
       "      <td>100, 100, 70</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>-7</td>\n",
       "      <td>340</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80, 90, 90</td>\n",
       "      <td>85, 99</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>260</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90, 99</td>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>-4</td>\n",
       "      <td>189</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60, 50</td>\n",
       "      <td>90, 60</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>-4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90, 90, 70</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90,5</td>\n",
       "      <td>80,9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100, 80, 40, 80</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>-3</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  varsta  gen_coded  iesit_des  lucrati  comportamentul  \\\n",
       "0           0      22          2          2        0               0   \n",
       "1           1      23          2          3        0               1   \n",
       "2           2      25          2          1        1               1   \n",
       "3           3      21          2          3        2               0   \n",
       "4           4      24          2          1        1               2   \n",
       "5           5      22          2          2        0               1   \n",
       "6           6      25          1          5        1               1   \n",
       "7           7      27          2          2        1               1   \n",
       "8           8      19          2          2        0               3   \n",
       "9           9      25          2          2        1               2   \n",
       "\n",
       "     scor_motive_nu scor_motive_da  ok_actiuni_1  confuz_1  ...  P_1  P_2  \\\n",
       "0  80, 100, 100, 60   100, 100, 70             9         2  ...   50   20   \n",
       "1        80, 90, 90         85, 99             8         9  ...   80   80   \n",
       "2            90, 99             97             8         3  ...   30   30   \n",
       "3            60, 50         90, 60             8         7  ...   50   50   \n",
       "4               100             80            10         2  ...   70   90   \n",
       "5        90, 90, 70            100             9         8  ...    0   90   \n",
       "6              90,5           80,9             5         1  ...    0    0   \n",
       "7   100, 80, 40, 80            100             9         2  ...   10   50   \n",
       "8                90            100             8         3  ...   50   70   \n",
       "9                90             10            10         1  ...    0    0   \n",
       "\n",
       "   schimbat  len_motive_nu  len_motive_da  scor_em_neg_inainte  \\\n",
       "0         0              4              3                   18   \n",
       "1         1              3              2                   21   \n",
       "2         0              2              1                   13   \n",
       "3         1              2              2                   19   \n",
       "4         1              1              1                   13   \n",
       "5         1              3              1                   20   \n",
       "6         0              2              2                    7   \n",
       "7         1              4              1                   17   \n",
       "8         1              1              1                   18   \n",
       "9         0              1              1                   12   \n",
       "\n",
       "   scor_em_neg_dupa  scor_diferenta_b_a  sum_motive_nu  sum_motive_da  \n",
       "0                25                  -7            340            270  \n",
       "1                16                   5            260            184  \n",
       "2                17                  -4            189             97  \n",
       "3                20                  -1            110            150  \n",
       "4                17                  -4            100             80  \n",
       "5                17                   3            250            100  \n",
       "6                10                  -3             95             89  \n",
       "7                17                   0            300            100  \n",
       "8                21                  -3             90            100  \n",
       "9                12                   0             90             10  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('dff_final.xlsx')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'varsta', 'gen_coded', 'iesit_des', 'lucrati',\n",
       "       'comportamentul', 'scor_motive_nu', 'scor_motive_da', 'ok_actiuni_1',\n",
       "       'confuz_1', 'frustrat_1', 'ok_actiuni_2', 'confuz_2', 'frustrat_2',\n",
       "       'negativitate_impact', 'urgenta_schimbarii', 'P_1', 'P_2', 'schimbat',\n",
       "       'len_motive_nu', 'len_motive_da', 'scor_em_neg_inainte',\n",
       "       'scor_em_neg_dupa', 'scor_diferenta_b_a', 'sum_motive_nu',\n",
       "       'sum_motive_da'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Unnamed: 0','scor_motive_nu', 'scor_motive_da'], index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varsta</th>\n",
       "      <th>gen_coded</th>\n",
       "      <th>iesit_des</th>\n",
       "      <th>lucrati</th>\n",
       "      <th>comportamentul</th>\n",
       "      <th>ok_actiuni_1</th>\n",
       "      <th>confuz_1</th>\n",
       "      <th>frustrat_1</th>\n",
       "      <th>ok_actiuni_2</th>\n",
       "      <th>confuz_2</th>\n",
       "      <th>...</th>\n",
       "      <th>P_1</th>\n",
       "      <th>P_2</th>\n",
       "      <th>schimbat</th>\n",
       "      <th>len_motive_nu</th>\n",
       "      <th>len_motive_da</th>\n",
       "      <th>scor_em_neg_inainte</th>\n",
       "      <th>scor_em_neg_dupa</th>\n",
       "      <th>scor_diferenta_b_a</th>\n",
       "      <th>sum_motive_nu</th>\n",
       "      <th>sum_motive_da</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>-7</td>\n",
       "      <td>340</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>-4</td>\n",
       "      <td>189</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>-4</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>271</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>185</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    varsta  gen_coded  iesit_des  lucrati  comportamentul  ok_actiuni_1  \\\n",
       "0       22          2          2        0               0             9   \n",
       "2       25          2          1        1               1             8   \n",
       "3       21          2          3        2               0             8   \n",
       "4       24          2          1        1               2            10   \n",
       "5       22          2          2        0               1             9   \n",
       "..     ...        ...        ...      ...             ...           ...   \n",
       "69      23          2          1        1               2            10   \n",
       "70      21          2          1        1               1             8   \n",
       "71      26          1          3        1               2            10   \n",
       "72      20          2          1        0               0             7   \n",
       "73      20          2          1        0               0             7   \n",
       "\n",
       "    confuz_1  frustrat_1  ok_actiuni_2  confuz_2  ...  P_1  P_2  schimbat  \\\n",
       "0          2           7             7         8  ...   50   20         0   \n",
       "2          3           2             7         6  ...   30   30         0   \n",
       "3          7           4             6         9  ...   50   50         1   \n",
       "4          2           1             7         6  ...   70   90         1   \n",
       "5          8           3             7         6  ...    0   90         1   \n",
       "..       ...         ...           ...       ...  ...  ...  ...       ...   \n",
       "69         1           1             8         1  ...   50   50         1   \n",
       "70         4           2             5         4  ...   15   25         0   \n",
       "71         1           8            10         1  ...    0    0         0   \n",
       "72         6           2             7         4  ...   75   80         1   \n",
       "73         6           2             7         4  ...   75   80         1   \n",
       "\n",
       "    len_motive_nu  len_motive_da  scor_em_neg_inainte  scor_em_neg_dupa  \\\n",
       "0               4              3                   18                25   \n",
       "2               2              1                   13                17   \n",
       "3               2              2                   19                20   \n",
       "4               1              1                   13                17   \n",
       "5               3              1                   20                17   \n",
       "..            ...            ...                  ...               ...   \n",
       "69              4              1                   12                11   \n",
       "70              3              1                   14                15   \n",
       "71              2              1                   19                19   \n",
       "72              2              2                   15                13   \n",
       "73              2              2                   15                13   \n",
       "\n",
       "    scor_diferenta_b_a  sum_motive_nu  sum_motive_da  \n",
       "0                   -7            340            270  \n",
       "2                   -4            189             97  \n",
       "3                   -1            110            150  \n",
       "4                   -4            100             80  \n",
       "5                    3            250            100  \n",
       "..                 ...            ...            ...  \n",
       "69                   1            271             30  \n",
       "70                  -1            185             80  \n",
       "71                   0            180             30  \n",
       "72                   2            105            170  \n",
       "73                   2            105            170  \n",
       "\n",
       "[73 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ok_actiuni_1_R'] = df['ok_actiuni_1'].apply(lambda row: np.abs(row-11))\n",
    "df['ok_actiuni_2_R'] = df['ok_actiuni_2'].apply(lambda row: np.abs(row-11))\n",
    "df['scor_em_neg_inainte'] = df['ok_actiuni_1_R'] + df['confuz_1'] + df['frustrat_1']\n",
    "df['scor_em_neg_dupa'] =  df['ok_actiuni_2_R'] + df['confuz_2'] + df['frustrat_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scor_diferenta_b_a'] = df['scor_em_neg_inainte'] - df['scor_em_neg_dupa']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CD'] = ((df['negativitate_impact'] * df['urgenta_schimbarii'])**2  \n",
    "+ (df['scor_em_neg_dupa'] / df['scor_em_neg_inainte']) \n",
    "* ((df['sum_motive_da'].mean()*df['len_motive_da'] * df['sum_motive_da'] ) \n",
    "/ ((df['sum_motive_nu'].mean()*df['len_motive_nu'] * df['sum_motive_nu']))))*((df['P_1']+df['P_2'])**2)/400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CD_LF'] = (df['len_motive_da'] * df['sum_motive_da'] )/ (df['len_motive_nu'] * df['sum_motive_nu'] + df['len_motive_da'] * df['sum_motive_da'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varsta</th>\n",
       "      <th>ok_actiuni_1</th>\n",
       "      <th>confuz_1</th>\n",
       "      <th>frustrat_1</th>\n",
       "      <th>ok_actiuni_2</th>\n",
       "      <th>confuz_2</th>\n",
       "      <th>frustrat_2</th>\n",
       "      <th>negativitate_impact</th>\n",
       "      <th>urgenta_schimbarii</th>\n",
       "      <th>P_1</th>\n",
       "      <th>...</th>\n",
       "      <th>comportamentul_2</th>\n",
       "      <th>comportamentul_3</th>\n",
       "      <th>comportamentul_4</th>\n",
       "      <th>comportamentul_5</th>\n",
       "      <th>comportamentul_6</th>\n",
       "      <th>iesit_des_1</th>\n",
       "      <th>iesit_des_2</th>\n",
       "      <th>iesit_des_3</th>\n",
       "      <th>iesit_des_4</th>\n",
       "      <th>iesit_des_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    varsta  ok_actiuni_1  confuz_1  frustrat_1  ok_actiuni_2  confuz_2  \\\n",
       "0       22             9         2           7             7         8   \n",
       "2       25             8         3           2             7         6   \n",
       "3       21             8         7           4             6         9   \n",
       "4       24            10         2           1             7         6   \n",
       "5       22             9         8           3             7         6   \n",
       "..     ...           ...       ...         ...           ...       ...   \n",
       "69      23            10         1           1             8         1   \n",
       "70      21             8         4           2             5         4   \n",
       "71      26            10         1           8            10         1   \n",
       "72      20             7         6           2             7         4   \n",
       "73      20             7         6           2             7         4   \n",
       "\n",
       "    frustrat_2  negativitate_impact  urgenta_schimbarii  P_1  ...  \\\n",
       "0           10                    9                   6   50  ...   \n",
       "2            4                    2                   3   30  ...   \n",
       "3            5                    7                  10   50  ...   \n",
       "4            4                    3                   8   70  ...   \n",
       "5            4                    3                   5    0  ...   \n",
       "..         ...                  ...                 ...  ...  ...   \n",
       "69           2                    2                   5   50  ...   \n",
       "70           6                    5                   6   15  ...   \n",
       "71           8                    0                   0    0  ...   \n",
       "72           2                    6                   5   75  ...   \n",
       "73           2                    6                   5   75  ...   \n",
       "\n",
       "    comportamentul_2  comportamentul_3  comportamentul_4  comportamentul_5  \\\n",
       "0                  0                 0                 0                 0   \n",
       "2                  0                 0                 0                 0   \n",
       "3                  0                 0                 0                 0   \n",
       "4                  1                 0                 0                 0   \n",
       "5                  0                 0                 0                 0   \n",
       "..               ...               ...               ...               ...   \n",
       "69                 1                 0                 0                 0   \n",
       "70                 0                 0                 0                 0   \n",
       "71                 1                 0                 0                 0   \n",
       "72                 0                 0                 0                 0   \n",
       "73                 0                 0                 0                 0   \n",
       "\n",
       "    comportamentul_6  iesit_des_1  iesit_des_2  iesit_des_3  iesit_des_4  \\\n",
       "0                  0            0            1            0            0   \n",
       "2                  0            1            0            0            0   \n",
       "3                  0            0            0            1            0   \n",
       "4                  0            1            0            0            0   \n",
       "5                  0            0            1            0            0   \n",
       "..               ...          ...          ...          ...          ...   \n",
       "69                 0            1            0            0            0   \n",
       "70                 0            1            0            0            0   \n",
       "71                 0            0            0            1            0   \n",
       "72                 0            1            0            0            0   \n",
       "73                 0            1            0            0            0   \n",
       "\n",
       "    iesit_des_5  \n",
       "0             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "5             0  \n",
       "..          ...  \n",
       "69            0  \n",
       "70            0  \n",
       "71            0  \n",
       "72            0  \n",
       "73            0  \n",
       "\n",
       "[73 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc = pd.get_dummies(dfc, columns = ['gen_coded', 'lucrati', 'comportamentul', 'iesit_des'])\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = dfc.drop(columns=['ok_actiuni_1_R', 'ok_actiuni_2_R'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dfc.loc[:, dfc.columns != 'schimbat'].values, np.ravel(dfc['schimbat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 37)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.,  9.,  2., ...,  0.,  0.,  0.],\n",
       "       [25.,  8.,  3., ...,  0.,  0.,  0.],\n",
       "       [21.,  8.,  7., ...,  1.,  0.,  0.],\n",
       "       ...,\n",
       "       [26., 10.,  1., ...,  1.,  0.,  0.],\n",
       "       [20.,  7.,  6., ...,  0.,  0.,  0.],\n",
       "       [20.,  7.,  6., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Modele neimpartite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NN_neimpartit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(50, input_dim = 36, activation = 'relu'))\n",
    "model_nn.add(Dense(40, activation = 'relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model_nn.add(Dense(20, activation = 'relu',kernel_regularizer=regularizers.l2(0.002)))\n",
    "model_nn.add(Dense(10, activation = 'relu',kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_nn.add(Dense(5, activation = 'relu'))\n",
    "model_nn.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_nn.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 7.5669 - accuracy: 0.8621\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 1.7913 - accuracy: 0.8621\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.6014 - accuracy: 0.8621\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 0s 224us/step - loss: 0.5852 - accuracy: 0.8793\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.5687 - accuracy: 0.8793\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.5595 - accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 0s 206us/step - loss: 0.5516 - accuracy: 0.8793\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 0s 137us/step - loss: 0.5441 - accuracy: 0.8966\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 0s 206us/step - loss: 0.5380 - accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.5320 - accuracy: 0.8966\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 0s 138us/step - loss: 0.5262 - accuracy: 0.8966\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 0s 224us/step - loss: 0.5186 - accuracy: 0.9138\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 0s 171us/step - loss: 0.5211 - accuracy: 0.8966\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 0s 137us/step - loss: 0.5122 - accuracy: 0.8966\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.4934 - accuracy: 0.9138\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 0s 206us/step - loss: 0.4845 - accuracy: 0.9138\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.90 - 0s 189us/step - loss: 0.4805 - accuracy: 0.9138\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 0s 241us/step - loss: 0.4760 - accuracy: 0.9138\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 0s 164us/step - loss: 0.4724 - accuracy: 0.9138\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 0s 171us/step - loss: 0.4694 - accuracy: 0.9138\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4667 - accuracy: 0.9138\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 0s 224us/step - loss: 0.4638 - accuracy: 0.9138\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4612 - accuracy: 0.9138\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4588 - accuracy: 0.9138\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4563 - accuracy: 0.9138\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 0s 224us/step - loss: 0.4541 - accuracy: 0.9138\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 0s 161us/step - loss: 0.4518 - accuracy: 0.9138\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 0s 171us/step - loss: 0.4496 - accuracy: 0.9138\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4477 - accuracy: 0.9138\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4455 - accuracy: 0.9138\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 0s 171us/step - loss: 0.4437 - accuracy: 0.9138\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4418 - accuracy: 0.9138\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 0s 206us/step - loss: 0.4398 - accuracy: 0.9138\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4381 - accuracy: 0.9138\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 0s 241us/step - loss: 0.4364 - accuracy: 0.9138\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4346 - accuracy: 0.9138\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 0s 154us/step - loss: 0.4330 - accuracy: 0.9138\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4314 - accuracy: 0.9138\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4297 - accuracy: 0.9138\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4281 - accuracy: 0.9138\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.4266 - accuracy: 0.9138\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4251 - accuracy: 0.9138\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 0s 207us/step - loss: 0.4237 - accuracy: 0.9138\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 0s 165us/step - loss: 0.4222 - accuracy: 0.9138\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4208 - accuracy: 0.9138\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 0s 224us/step - loss: 0.4195 - accuracy: 0.9138\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.4182 - accuracy: 0.9138\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4169 - accuracy: 0.9138\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 0s 206us/step - loss: 0.4156 - accuracy: 0.9138\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4144 - accuracy: 0.9138\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 0s 190us/step - loss: 0.4132 - accuracy: 0.9138\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4119 - accuracy: 0.9138\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.4107 - accuracy: 0.9138\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4096 - accuracy: 0.9138\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4084 - accuracy: 0.9138\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 1.00 - 0s 138us/step - loss: 0.4073 - accuracy: 0.9138\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4061 - accuracy: 0.9138\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.4050 - accuracy: 0.9138\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 0s 224us/step - loss: 0.4039 - accuracy: 0.9138\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4029 - accuracy: 0.9138\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.4019 - accuracy: 0.9138\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4008 - accuracy: 0.9138\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.4000 - accuracy: 0.9138\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3988 - accuracy: 0.9138\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3979 - accuracy: 0.9138\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.3970 - accuracy: 0.9138\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3960 - accuracy: 0.9138\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3950 - accuracy: 0.9138\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3942 - accuracy: 0.9138\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.3933 - accuracy: 0.9138\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.3924 - accuracy: 0.9138\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3915 - accuracy: 0.9138\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3907 - accuracy: 0.9138\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3899 - accuracy: 0.9138\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 0s 189us/step - loss: 0.3890 - accuracy: 0.9138\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 0s 138us/step - loss: 0.3882 - accuracy: 0.9138\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3874 - accuracy: 0.9138\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3866 - accuracy: 0.9138\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 0s 206us/step - loss: 0.3858 - accuracy: 0.9138\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3850 - accuracy: 0.9138\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3842 - accuracy: 0.9138\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3835 - accuracy: 0.9138\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3827 - accuracy: 0.9138\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3819 - accuracy: 0.9138\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3812 - accuracy: 0.9138\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3805 - accuracy: 0.9138\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3797 - accuracy: 0.9138\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3790 - accuracy: 0.9138\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3782 - accuracy: 0.9138\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3776 - accuracy: 0.9138\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3768 - accuracy: 0.9138\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 0s 138us/step - loss: 0.3761 - accuracy: 0.9138\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 0s 138us/step - loss: 0.3754 - accuracy: 0.9138\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3748 - accuracy: 0.9138\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3740 - accuracy: 0.9138\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3733 - accuracy: 0.9138\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3727 - accuracy: 0.9138\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 0s 155us/step - loss: 0.3720 - accuracy: 0.9138\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 0s 138us/step - loss: 0.3713 - accuracy: 0.9138\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 0s 172us/step - loss: 0.3706 - accuracy: 0.9138\n",
      "58/58 [==============================] - 0s 447us/step\n",
      "accuracys: 91.37930870056152\n"
     ]
    }
   ],
   "source": [
    "model_nn.fit(X_train, y_train, epochs = 100, batch_size = 10)\n",
    "scores = model_nn.evaluate(X_train, y_train)\n",
    "print('{}s: {}'.format(model_nn.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 67us/step\n",
      "accuracys: 80.0000011920929\n"
     ]
    }
   ],
   "source": [
    "scores = model_nn.evaluate(X_test, y_test)\n",
    "print('{}s: {}'.format(model_nn.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "save_model(model_nn, './saved_model_nn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random forest _ neimpartit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=4, random_state = 0, criterion='gini')\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For i = 1, train = 0.9310344827586207, test = 0.6666666666666666\n",
      "For i = 2, train = 0.9482758620689655, test = 0.7333333333333333\n",
      "For i = 3, train = 0.9655172413793104, test = 0.7333333333333333\n",
      "For i = 4, train = 1.0, test = 0.7333333333333333\n",
      "For i = 5, train = 1.0, test = 0.6666666666666666\n",
      "For i = 6, train = 1.0, test = 0.7333333333333333\n",
      "For i = 7, train = 1.0, test = 0.7333333333333333\n",
      "For i = 8, train = 1.0, test = 0.7333333333333333\n",
      "For i = 9, train = 1.0, test = 0.7333333333333333\n",
      "For i = 10, train = 1.0, test = 0.7333333333333333\n",
      "For i = 11, train = 1.0, test = 0.7333333333333333\n",
      "For i = 12, train = 1.0, test = 0.7333333333333333\n",
      "For i = 13, train = 1.0, test = 0.7333333333333333\n",
      "For i = 14, train = 1.0, test = 0.7333333333333333\n",
      "For i = 15, train = 1.0, test = 0.7333333333333333\n",
      "For i = 16, train = 1.0, test = 0.7333333333333333\n",
      "For i = 17, train = 1.0, test = 0.7333333333333333\n",
      "For i = 18, train = 1.0, test = 0.7333333333333333\n",
      "For i = 19, train = 1.0, test = 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    rfc = RandomForestClassifier(max_depth= i, random_state = 0, criterion='gini')\n",
    "    rfc.fit(X_train, y_train)\n",
    "    print(\"For i = {}, train = {}, test = {}\".format(i,rfc.score(X_train, y_train), rfc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.02077\n",
      "Feature: 1, Score: 0.00794\n",
      "Feature: 2, Score: 0.02073\n",
      "Feature: 3, Score: 0.01174\n",
      "Feature: 4, Score: 0.02303\n",
      "Feature: 5, Score: 0.01337\n",
      "Feature: 6, Score: 0.01157\n",
      "Feature: 7, Score: 0.03758\n",
      "Feature: 8, Score: 0.09706\n",
      "Feature: 9, Score: 0.16863\n",
      "Feature: 10, Score: 0.19031\n",
      "Feature: 11, Score: 0.01403\n",
      "Feature: 12, Score: 0.00391\n",
      "Feature: 13, Score: 0.02788\n",
      "Feature: 14, Score: 0.02057\n",
      "Feature: 15, Score: 0.01146\n",
      "Feature: 16, Score: 0.02253\n",
      "Feature: 17, Score: 0.02177\n",
      "Feature: 18, Score: 0.23846\n",
      "Feature: 19, Score: 0.00808\n",
      "Feature: 20, Score: 0.00075\n",
      "Feature: 21, Score: 0.00171\n",
      "Feature: 22, Score: 0.00424\n",
      "Feature: 23, Score: 0.00181\n",
      "Feature: 24, Score: 0.00027\n",
      "Feature: 25, Score: 0.00215\n",
      "Feature: 26, Score: 0.00214\n",
      "Feature: 27, Score: 0.00116\n",
      "Feature: 28, Score: 0.00000\n",
      "Feature: 29, Score: 0.00070\n",
      "Feature: 30, Score: 0.00028\n",
      "Feature: 31, Score: 0.00203\n",
      "Feature: 32, Score: 0.00407\n",
      "Feature: 33, Score: 0.00235\n",
      "Feature: 34, Score: 0.00131\n",
      "Feature: 35, Score: 0.00363\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get importance\n",
    "importance =rfc.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: is varsta\n",
      "Feature 1: is ok_actiuni_1\n",
      "Feature 2: is confuz_1\n",
      "Feature 3: is frustrat_1\n",
      "Feature 4: is ok_actiuni_2\n",
      "Feature 5: is confuz_2\n",
      "Feature 6: is frustrat_2\n",
      "Feature 7: is negativitate_impact\n",
      "Feature 8: is urgenta_schimbarii\n",
      "Feature 9: is P_1\n",
      "Feature 10: is P_2\n",
      "Feature 11: is schimbat\n",
      "Feature 12: is len_motive_nu\n",
      "Feature 13: is len_motive_da\n",
      "Feature 14: is scor_em_neg_inainte\n",
      "Feature 15: is scor_em_neg_dupa\n",
      "Feature 16: is scor_diferenta_b_a\n",
      "Feature 17: is sum_motive_nu\n",
      "Feature 18: is sum_motive_da\n",
      "Feature 19: is CD\n",
      "Feature 20: is gen_coded_1\n",
      "Feature 21: is gen_coded_2\n",
      "Feature 22: is lucrati_0\n",
      "Feature 23: is lucrati_1\n",
      "Feature 24: is lucrati_2\n",
      "Feature 25: is comportamentul_0\n",
      "Feature 26: is comportamentul_1\n",
      "Feature 27: is comportamentul_2\n",
      "Feature 28: is comportamentul_3\n",
      "Feature 29: is comportamentul_4\n",
      "Feature 30: is comportamentul_5\n",
      "Feature 31: is comportamentul_6\n",
      "Feature 32: is iesit_des_1\n",
      "Feature 33: is iesit_des_2\n",
      "Feature 34: is iesit_des_3\n",
      "Feature 35: is iesit_des_4\n",
      "Feature 36: is iesit_des_5\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dfc.columns)):\n",
    "    print('Feature {}: is {}'.format(i, dfc.columns[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM_neimpartit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8103448275862069"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ecuatia propusa: CD (Cognitive Dissonance)_ neimpartit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1 = np.reshape(np.ravel(dfc['CD']),(-1,1)), np.ravel(dfc['schimbat'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1,Y1, test_size = 0.20, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression().fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7931034482758621"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X1_test,y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.reshape(np.ravel(dfc['CD_LF']),(-1,1)), np.ravel(dfc['schimbat'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(x,y, test_size = 0.20, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression().fit(x_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5517241379310345"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(x_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impartirea esantionului in grupul bazat pe disonanta cognitiva\n",
    "\n",
    "* selectia se va face dupa variabila scor_diferenta_b_a (inainte dupa videoclipuri)\n",
    "* daca scorul la aceasta variabila este negativ, atunci persoana respectiva a experimentat disonanta cognitiva\n",
    "* daca scorul este mai mare sau egal cu 0 atunci se considera cu nu a experimentat disonanta cognitiva\n",
    "* grupul disonantei se va numi DC, iar grupul care nu este in disonanta se va numi NDC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['varsta', 'ok_actiuni_1', 'confuz_1', 'frustrat_1', 'ok_actiuni_2',\n",
       "       'confuz_2', 'frustrat_2', 'negativitate_impact', 'urgenta_schimbarii',\n",
       "       'P_1', 'P_2', 'schimbat', 'len_motive_nu', 'len_motive_da',\n",
       "       'scor_em_neg_inainte', 'scor_em_neg_dupa', 'scor_diferenta_b_a',\n",
       "       'sum_motive_nu', 'sum_motive_da', 'CD', 'gen_coded_1', 'gen_coded_2',\n",
       "       'lucrati_0', 'lucrati_1', 'lucrati_2', 'comportamentul_0',\n",
       "       'comportamentul_1', 'comportamentul_2', 'comportamentul_3',\n",
       "       'comportamentul_4', 'comportamentul_5', 'comportamentul_6',\n",
       "       'iesit_des_1', 'iesit_des_2', 'iesit_des_3', 'iesit_des_4',\n",
       "       'iesit_des_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impartirea setului de date in cele 2 grupuri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC = dfc[dfc['scor_diferenta_b_a']<0]\n",
    "NDC = dfc[dfc['scor_diferenta_b_a']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 44\n"
     ]
    }
   ],
   "source": [
    "print(len(DC), len(NDC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impartirea in training si test a grupului cu disonanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, Y2 = DC.loc[:, DC.columns != 'schimbat'].values, np.ravel(DC['schimbat'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2,Y2, test_size = 0.20, random_state = 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impartirea in training si test a grupului fara disonanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3, Y3 = NDC.loc[:, NDC.columns != 'schimbat'].values, np.ravel(NDC['schimbat'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3,Y3, test_size = 0.20, random_state = 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Modele impartite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NN_impartit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn1 = Sequential()\n",
    "model_nn1.add(Dense(50, input_dim = 36, activation = 'relu'))\n",
    "model_nn1.add(Dense(40, activation = 'relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model_nn1.add(Dense(20, activation = 'relu',kernel_regularizer=regularizers.l2(0.002)))\n",
    "model_nn1.add(Dense(10, activation = 'relu',kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_nn1.add(Dense(5, activation = 'relu'))\n",
    "model_nn1.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_nn1.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn2 = Sequential()\n",
    "model_nn2.add(Dense(50, input_dim = 36, activation = 'relu'))\n",
    "model_nn2.add(Dense(40, activation = 'relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "model_nn2.add(Dense(20, activation = 'relu',kernel_regularizer=regularizers.l2(0.002)))\n",
    "model_nn2.add(Dense(10, activation = 'relu',kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_nn2.add(Dense(5, activation = 'relu'))\n",
    "model_nn2.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_nn2.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8741 - accuracy: 0.5652\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.8610 - accuracy: 0.6957\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 281us/step - loss: 0.8577 - accuracy: 0.6957\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 241us/step - loss: 0.8386 - accuracy: 0.6957\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.8085 - accuracy: 0.7826\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.7837 - accuracy: 0.8261\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 416us/step - loss: 0.7680 - accuracy: 0.8696\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 237us/step - loss: 0.7332 - accuracy: 0.8696\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.7125 - accuracy: 0.8696\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.7055 - accuracy: 0.8261\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 391us/step - loss: 0.6937 - accuracy: 0.8261\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.6863 - accuracy: 0.8696\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.6772 - accuracy: 0.8696\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 280us/step - loss: 0.6728 - accuracy: 0.8696\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 424us/step - loss: 0.6679 - accuracy: 0.8696\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.6633 - accuracy: 0.8696\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 254us/step - loss: 0.6584 - accuracy: 0.8696\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.6540 - accuracy: 0.8696\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.6494 - accuracy: 0.8696\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 304us/step - loss: 0.6457 - accuracy: 0.8696\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 334us/step - loss: 0.6424 - accuracy: 0.8696\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 216us/step - loss: 0.6388 - accuracy: 0.8696\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.6357 - accuracy: 0.8696\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.6325 - accuracy: 0.8696\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 272us/step - loss: 0.6297 - accuracy: 0.8696\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 242us/step - loss: 0.6268 - accuracy: 0.8696\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 173us/step - loss: 0.6243 - accuracy: 0.8696\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 173us/step - loss: 0.6219 - accuracy: 0.8696\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.6194 - accuracy: 0.8696\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 206us/step - loss: 0.6192 - accuracy: 0.8261\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.6152 - accuracy: 0.8696\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.6134 - accuracy: 0.8696\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 173us/step - loss: 0.6117 - accuracy: 0.8696\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 215us/step - loss: 0.6101 - accuracy: 0.8696\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.6080 - accuracy: 0.8696\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 304us/step - loss: 0.6058 - accuracy: 0.8696\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 230us/step - loss: 0.6037 - accuracy: 0.8696\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 216us/step - loss: 0.6016 - accuracy: 0.8696\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.5998 - accuracy: 0.8696\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 347us/step - loss: 0.5979 - accuracy: 0.8696\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5962 - accuracy: 0.8696\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 216us/step - loss: 0.5944 - accuracy: 0.8696\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5929 - accuracy: 0.8696\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 402us/step - loss: 0.5912 - accuracy: 0.8696\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 229us/step - loss: 0.5897 - accuracy: 0.8696\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5881 - accuracy: 0.8696\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5866 - accuracy: 0.8696\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.5851 - accuracy: 0.8696\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 215us/step - loss: 0.5837 - accuracy: 0.8696\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5823 - accuracy: 0.8696\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 304us/step - loss: 0.5808 - accuracy: 0.8696\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5794 - accuracy: 0.8696\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 216us/step - loss: 0.5779 - accuracy: 0.8696\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 170us/step - loss: 0.5765 - accuracy: 0.8696\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 347us/step - loss: 0.5751 - accuracy: 0.8696\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 306us/step - loss: 0.5737 - accuracy: 0.8696\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5725 - accuracy: 0.8696\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5711 - accuracy: 0.8696\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.5698 - accuracy: 0.8696\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5686 - accuracy: 0.8696\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 192us/step - loss: 0.5672 - accuracy: 0.8696\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 391us/step - loss: 0.5660 - accuracy: 0.8696\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 239us/step - loss: 0.5648 - accuracy: 0.8696\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 261us/step - loss: 0.5635 - accuracy: 0.8696\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5624 - accuracy: 0.8696\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 231us/step - loss: 0.5612 - accuracy: 0.8696\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 347us/step - loss: 0.5601 - accuracy: 0.8696\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.5589 - accuracy: 0.8696\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.5579 - accuracy: 0.8696\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5579 - accuracy: 0.8696\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 334us/step - loss: 0.5558 - accuracy: 0.8696\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 243us/step - loss: 0.5549 - accuracy: 0.8696\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5541 - accuracy: 0.8696\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5534 - accuracy: 0.8696\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 281us/step - loss: 0.5526 - accuracy: 0.8696\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 200us/step - loss: 0.5515 - accuracy: 0.8696\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 269us/step - loss: 0.5501 - accuracy: 0.8696\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5488 - accuracy: 0.8696\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 302us/step - loss: 0.5475 - accuracy: 0.8696\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 242us/step - loss: 0.5464 - accuracy: 0.8696\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 304us/step - loss: 0.5453 - accuracy: 0.8696\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 262us/step - loss: 0.5443 - accuracy: 0.8696\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.5432 - accuracy: 0.8696\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5424 - accuracy: 0.8696\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.5414 - accuracy: 0.8696\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 257us/step - loss: 0.5405 - accuracy: 0.8696\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 253us/step - loss: 0.5397 - accuracy: 0.8696\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5387 - accuracy: 0.8696\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5379 - accuracy: 0.8696\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 304us/step - loss: 0.5370 - accuracy: 0.8696\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5362 - accuracy: 0.8696\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 694us/step - loss: 0.5353 - accuracy: 0.8696\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5345 - accuracy: 0.8696\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5337 - accuracy: 0.8696\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5327 - accuracy: 0.8696\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 212us/step - loss: 0.5319 - accuracy: 0.8696\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 217us/step - loss: 0.5311 - accuracy: 0.8696\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 260us/step - loss: 0.5302 - accuracy: 0.8696\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 303us/step - loss: 0.5293 - accuracy: 0.8696\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 199us/step - loss: 0.5286 - accuracy: 0.8696\n",
      "23/23 [==============================] - 0s 87us/step\n",
      "accuracys: 82.6086938381195\n"
     ]
    }
   ],
   "source": [
    "model_nn1.fit(X2_train, y2_train, epochs = 100, batch_size = 10)\n",
    "scores = model_nn.evaluate(X2_train, y2_train)\n",
    "print('{}s: {}'.format(model_nn.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 215.4623 - accuracy: 0.6571\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 173us/step - loss: 129.4378 - accuracy: 0.6571\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 191us/step - loss: 16.8335 - accuracy: 0.6571\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 199us/step - loss: 26.1842 - accuracy: 0.6571\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 275us/step - loss: 5.8295 - accuracy: 0.6571\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 222us/step - loss: 5.3561 - accuracy: 0.6571\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 269us/step - loss: 4.7418 - accuracy: 0.6571\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 231us/step - loss: 4.0627 - accuracy: 0.6571\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 275us/step - loss: 3.4591 - accuracy: 0.6571\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 2.7723 - accuracy: 0.6571\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 259us/step - loss: 2.0595 - accuracy: 0.6571\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 190us/step - loss: 1.4011 - accuracy: 0.6286\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.9698 - accuracy: 0.6857\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 285us/step - loss: 0.5835 - accuracy: 0.7714\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.4352 - accuracy: 0.9143\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 226us/step - loss: 0.4011 - accuracy: 0.9143\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 285us/step - loss: 0.3876 - accuracy: 0.8857\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.3771 - accuracy: 0.8857\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 197us/step - loss: 0.3668 - accuracy: 0.8857\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 256us/step - loss: 0.3604 - accuracy: 0.9143\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.3550 - accuracy: 0.9143\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 200us/step - loss: 0.3485 - accuracy: 0.9143\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 279us/step - loss: 0.3467 - accuracy: 0.8857\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.3395 - accuracy: 0.9143\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 256us/step - loss: 0.3360 - accuracy: 0.9143\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 200us/step - loss: 0.3327 - accuracy: 0.9143\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 199us/step - loss: 0.3288 - accuracy: 0.9143\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 256us/step - loss: 0.3254 - accuracy: 0.9143\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 200us/step - loss: 0.3227 - accuracy: 0.9143\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 246us/step - loss: 0.3205 - accuracy: 0.9143\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.3180 - accuracy: 0.9143\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 199us/step - loss: 0.3162 - accuracy: 0.9143\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 256us/step - loss: 0.3144 - accuracy: 0.9143\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 213us/step - loss: 0.3123 - accuracy: 0.9143\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 187us/step - loss: 0.3103 - accuracy: 0.9143\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 345us/step - loss: 0.3084 - accuracy: 0.9143\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 196us/step - loss: 0.3067 - accuracy: 0.9143\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.3049 - accuracy: 0.9143\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 286us/step - loss: 0.3034 - accuracy: 0.9143\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.3020 - accuracy: 0.9143\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 256us/step - loss: 0.3018 - accuracy: 0.9143\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 285us/step - loss: 0.2995 - accuracy: 0.9143\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2986 - accuracy: 0.9143\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 199us/step - loss: 0.2975 - accuracy: 0.9143\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 254us/step - loss: 0.2964 - accuracy: 0.9143\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 201us/step - loss: 0.2953 - accuracy: 0.9143\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 199us/step - loss: 0.2941 - accuracy: 0.9143\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 256us/step - loss: 0.2930 - accuracy: 0.9143\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 203us/step - loss: 0.2920 - accuracy: 0.9143\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2909 - accuracy: 0.9143\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 251us/step - loss: 0.2900 - accuracy: 0.9143\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2894 - accuracy: 0.9143\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 272us/step - loss: 0.2888 - accuracy: 0.9143\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 283us/step - loss: 0.2884 - accuracy: 0.9143\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2875 - accuracy: 0.9143\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2866 - accuracy: 0.9143\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 265us/step - loss: 0.2859 - accuracy: 0.9143\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2849 - accuracy: 0.9143\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 256us/step - loss: 0.2840 - accuracy: 0.9143\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 252us/step - loss: 0.2832 - accuracy: 0.9143\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2825 - accuracy: 0.9143\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2818 - accuracy: 0.9143\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2810 - accuracy: 0.9143\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 200us/step - loss: 0.2802 - accuracy: 0.9143\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2799 - accuracy: 0.9143\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 285us/step - loss: 0.2789 - accuracy: 0.9143\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2784 - accuracy: 0.9143\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2777 - accuracy: 0.9143\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2771 - accuracy: 0.9143\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 213us/step - loss: 0.2766 - accuracy: 0.9143\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 214us/step - loss: 0.2762 - accuracy: 0.9143\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2757 - accuracy: 0.9143\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 203us/step - loss: 0.2751 - accuracy: 0.9143\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 231us/step - loss: 0.2746 - accuracy: 0.9143\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 200us/step - loss: 0.2741 - accuracy: 0.9143\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 254us/step - loss: 0.2737 - accuracy: 0.9143\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2732 - accuracy: 0.9143\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 171us/step - loss: 0.2728 - accuracy: 0.9143\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2723 - accuracy: 0.9143\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 217us/step - loss: 0.2719 - accuracy: 0.9143\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2715 - accuracy: 0.9143\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 246us/step - loss: 0.2712 - accuracy: 0.9143\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 178us/step - loss: 0.2708 - accuracy: 0.9143\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 261us/step - loss: 0.2711 - accuracy: 0.9143\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 199us/step - loss: 0.2703 - accuracy: 0.9143\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2700 - accuracy: 0.9143\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 242us/step - loss: 0.2697 - accuracy: 0.9143\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 216us/step - loss: 0.2693 - accuracy: 0.9143\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 229us/step - loss: 0.2689 - accuracy: 0.9143\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 227us/step - loss: 0.2685 - accuracy: 0.9143\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 285us/step - loss: 0.2681 - accuracy: 0.9143\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 332us/step - loss: 0.2677 - accuracy: 0.9143\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 313us/step - loss: 0.2674 - accuracy: 0.9143\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 274us/step - loss: 0.2671 - accuracy: 0.9143\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 256us/step - loss: 0.2667 - accuracy: 0.9143\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 227us/step - loss: 0.2664 - accuracy: 0.9143\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.2662 - accuracy: 0.9143\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 199us/step - loss: 0.2658 - accuracy: 0.9143\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 286us/step - loss: 0.2656 - accuracy: 0.9143\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 199us/step - loss: 0.2653 - accuracy: 0.9143\n",
      "35/35 [==============================] - 0s 924us/step\n",
      "accuracys: 91.42857193946838\n"
     ]
    }
   ],
   "source": [
    "model_nn2.fit(X3_train, y3_train, epochs = 100, batch_size = 10)\n",
    "scores = model_nn2.evaluate(X3_train, y3_train)\n",
    "print('{}s: {}'.format(model_nn2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step\n",
      "accuracys: 66.66666865348816\n"
     ]
    }
   ],
   "source": [
    "scores = model_nn1.evaluate(X2_test, y2_test)\n",
    "print('{}s: {}'.format(model_nn1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 219us/step\n",
      "accuracys: 77.77777910232544\n"
     ]
    }
   ],
   "source": [
    "scores = model_nn2.evaluate(X3_test, y3_test)\n",
    "print('{}s: {}'.format(model_nn2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random forest_impartit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For i = 1, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 2, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 3, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 4, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 5, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 6, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 7, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 8, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 9, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 10, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 11, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 12, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 13, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 14, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 15, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 16, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 17, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 18, train = 0.9565217391304348, test = 0.8333333333333334\n",
      "For i = 19, train = 0.9565217391304348, test = 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    rfc2 = RandomForestClassifier(max_depth= i, random_state = 0, criterion='gini')\n",
    "    rfc2.fit(X2_train, y2_train)\n",
    "    print(\"For i = {}, train = {}, test = {}\".format(i,rfc.score(X2_train, y2_train), rfc.score(X2_test, y2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For i = 1, train = 0.9428571428571428, test = 1.0\n",
      "For i = 2, train = 0.9428571428571428, test = 1.0\n",
      "For i = 3, train = 0.9428571428571428, test = 1.0\n",
      "For i = 4, train = 0.9428571428571428, test = 1.0\n",
      "For i = 5, train = 0.9428571428571428, test = 1.0\n",
      "For i = 6, train = 0.9428571428571428, test = 1.0\n",
      "For i = 7, train = 0.9428571428571428, test = 1.0\n",
      "For i = 8, train = 0.9428571428571428, test = 1.0\n",
      "For i = 9, train = 0.9428571428571428, test = 1.0\n",
      "For i = 10, train = 0.9428571428571428, test = 1.0\n",
      "For i = 11, train = 0.9428571428571428, test = 1.0\n",
      "For i = 12, train = 0.9428571428571428, test = 1.0\n",
      "For i = 13, train = 0.9428571428571428, test = 1.0\n",
      "For i = 14, train = 0.9428571428571428, test = 1.0\n",
      "For i = 15, train = 0.9428571428571428, test = 1.0\n",
      "For i = 16, train = 0.9428571428571428, test = 1.0\n",
      "For i = 17, train = 0.9428571428571428, test = 1.0\n",
      "For i = 18, train = 0.9428571428571428, test = 1.0\n",
      "For i = 19, train = 0.9428571428571428, test = 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    rfc3 = RandomForestClassifier(max_depth= i, random_state = 0, criterion='gini')\n",
    "    rfc3.fit(X3_train, y3_train)\n",
    "    print(\"For i = {}, train = {}, test = {}\".format(i,rfc.score(X3_train, y3_train), rfc.score(X3_test, y3_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SVM_impartit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm2 = svm.SVC()\n",
    "svm2.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm3 = svm.SVC()\n",
    "svm3.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.score(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285714285714286"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm3.score(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm3.score(X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CD_impartit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impartirea celor 2 grupuri in antrenament si test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4, Y4 = np.reshape(np.ravel(DC['CD']),(-1,1)), np.ravel(DC['schimbat'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4,Y4, test_size = 0.20, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5, Y5 = np.reshape(np.ravel(NDC['CD']),(-1,1)), np.ravel(NDC['schimbat'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5,Y5, test_size = 0.20, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr4 = LogisticRegression().fit(X4_train,y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr5 = LogisticRegression().fit(X5_train,y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7391304347826086"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr4.score(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr5.score(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr4.score(X4_test, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr5.score(X5_test, y5_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
